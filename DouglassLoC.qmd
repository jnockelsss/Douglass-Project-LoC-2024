---
title: "DouglassLoC"
format: pdf
editor: visual
---

## "Leveraging Accurate and Accessible Texts at the Library of Congress. A Study of Frederick Douglass’s Autobiographical Writing (1845 - 1895)"

In displaying how Automated Text Recognition (ATR) transcriptions can open up digital scholarship, through text analysis, this Quarto document allows for reproducible and reusable research through R scripting. The processes of importing transcription data, pre-processing, exploration, modelling and reporting are shown. The necessity for blending ATR approaches with R is demonstrated with the below figure, highlighting the high error rate in using rudimentary OCR in providing accurate textual data sets to be interrogated against.

![ Figure 1, OCR confidence levels on Douglass Travel Diary (1886-1887)](figures/OCR Error/TesseractCon_LTFD_01.png)

In term of object names in the below code, each refers to an autobiographical work of the social campaigner and abolitionist Frederick Douglass (1818 - 1895), NLFD: Narrative Life of Frederick Douglass (1845); MBMF: My Bondage, My Freedom (1855), LTFD: Life and Times of Frederick Douglass (1881), DD: Douglass Diary (1886 - 1894). The first two chronological objects were pulled from Project Gutenberg, LTFD was uploaded as a .rtf file, DD being automatically transcribed and manually corrected using the ATR platform Transkribus and then uploaded as separated .txt files.

## General

```{r}
getwd()
setwd("~/Documents/Douglass2024/dataraw")
```

# Word Frequencies and Lexical Diversity

What similarities and constrasts can we gleam from Douglass's autobiographical writing, now that we have an accessible transcription of his Travel Diary? How did Douglass's writing develop? This section explores such themes.

```{r}
# packages #

library(readtext)
library(gutenbergr)
library(tidyverse)
library(tidytext)
library(tm)
library(scales)

# upload Douglass's wider biography from Project Gutenberg and convert into tidytext format #

NLFD.v <- gutenberg_download(23)
tidy_NLFD <- NLFD.v %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words)

MBMF.v <- gutenberg_download(202)
tidy_MBMF <- MBMF.v %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words)

LTFD.v <- readtext("/Users/joenockels/Documents/Douglass2024/dataraw/LTFD.rtf")
tidy_LTFD <- unnest_tokens(LTFD.v, word, text)
data("stop_words")
tidy_LTFD <- anti_join(tidy_LTFD, stop_words)

# upload Douglass's diary and pre-process in tm() package #

DD.v <- Corpus(DirSource("~/Documents/Douglass2024/dataraw/DD"))
writeLines(as.character(DD.v))
DD.v <- 
  tm_map(DD.v, content_transformer(removeNumbers)) %>%
  tm_map(content_transformer(removePunctuation)) %>%
  tm_map(content_transformer(stripWhitespace)) %>%
  tm_map(content_transformer(tolower)) %>%
  tm_map(content_transformer(removeWords), stopwords("english"))
  DD.dtm <- DocumentTermMatrix(DD.v)
  tidy_DD <- tidy(DD.dtm)
  tidy_DD <- tidy_DD %>%
    rename(word = term)
head(tidy_DD)

# basic word freqs for lexical diversity # TBC

freq <- colSums(as.matrix(DD.dtm))
freq[1:10]
freq_dec <- sort(freq, decreasing = TRUE)
freq_dec[1:20]
library(wordcloud2)
matrix <- as.matrix(DD.dtm)
words <- sort(colSums(matrix), decreasing = TRUE)
df <- data.frame(word = names(words), freq = words)
wordcloud2(data = df, size = 0.5)

# calculate the similarity of word freqs across the range of works #

frequency <- bind_rows(mutate(tidy_NLFD, work = "Narrative Life (1845)"),
                       mutate(tidy_MBMF, work = "My Bondage (1855)"),
                       mutate(tidy_LTFD, work = "Life and Times (1881)"),
                       mutate(tidy_DD, work = "Travel Diary")) %>%
    group_by(work, word) %>%
    summarise(count = n()) %>%
    group_by(work) %>%
    mutate(proportion = count / sum(count)) %>%
    ungroup() %>%
    pivot_wider(names_from = work, values_from = proportion) %>%
    pivot_longer(`Narrative Life (1845)`:`My Bondage (1855)`:`Life and    Times (1881)`, names_to = "work", values_to = "proportion")

# visualise #

ggplot(frequency, aes(x = proportion, y = `Travel Diary`, 
                      color = abs(`Travel Diary` - proportion))) +
  geom_abline(color = "gray40", lty = 2) +
  geom_jitter(alpha = 0.18, size = 1.5, width = 0.5, height = 0.5) +
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format()) +
  scale_color_gradient(low = "darkslategray4", high = "coral") +
  facet_wrap(~work, ncol = 4) +
  theme(legend.position="none") +
  labs(y = "Travel Diary (1886-1887)", x = NULL)


```

![Word freq similarity between Travel Diary (1886-1887) and Douglass biographies, the further the points amass around the line - the greater the similarity](figures/Word Frequencies/Rplot01.png)\
Figure Two, Word frequency similarity between Douglass's diary and wider autobiography, the closer each point (word token) appears to the line - the greater the similarity.

```{r}

# correlate results as a means of verifying visual #

cor.test(data = frequency[frequency$work == "Life and Times (1881)",],
         ~ proportion + `Travel Diary`)

# hapax correlation # TBC

autobiography.v <- c(DD.v, MBMF.v, NLFD.v)
novel.hapax.v <- lapply(autobiography.v, function(x), sum(x == 1))
novel.lengths.m <- do.call(rbind, lapply(autobiography.v, sum))
hapax.percentage <- novel.hapax.v / novel.lengths.m
hapax.percentge[order(hapax.percentage, decreasing = TRUE),]
barplot(hapax.percentage, beside = T, col = "grey")
        main = "Hapax across Douglass autobiographical writing"
        names.arg = c("DD", "MBMF", "NLFD")
# length of shorter DD impact hapax?
lengths.hapax.v <- cbind(novel.hapax.v, novel.lengths.m)
cor(lengths.hapax.v[, 1:3], lengths.hapax.v [, 4])

hapax_correlation <- cor(novel.hapax.v, novel.lengths.m)

# inverse wf to provide more weighting to less common terms # TBC

autobiography_tf_idf <- autobiography.v %>%
  bind_tf_idf(word, work, n)

autobiography_tf_idf %>%
  group_by(work) %>%
  slice_max(tf_idf, n = 15) %>%
  ungroup() %>%
  ggplot(aes(tf_idf, fct_reorder(word, tf_idf), fill = work)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~work, ncol = 2, scales = "free") +
  labs(x = "tf-idf", y = NULL)
```

## Word Dispersion

Prevailing scholarship (Martin, 1984: 175-176; 180) suggests Douglass in the 1850s-1860s placed God "off the stage", shifting from a powerful belief of divine determinism in human affairs to a more radical philosophy of social reform and religious liberalism. Nonetheless, as Williams (2002: 143-145) critiques Martin's (1984) assertion that for Douglass abolition superseded religion, a product Williams suggests of Martin's intellectual biography flattening Douglass as subject without needed narrative analysis. Instead, Williams (2022: 9) states, “Douglass was a Christian. His commitment to the institution of the church waned over time, but he maintained an abiding belief in the bedrock Christian story.” What occurred in Douglass's spiritual journey, was perhaps the development of more intrinsic faith: internalising his religious motive opposed to using it as a public justification for abolition (Allport, 1967; Williams, 2022: 5). As such, these findings must be measured against his complex biography. Nonetheless, is this shift to a more liberal religion indicated in relative wf data? Does Douglass no longer mention God explicitly? Or do these mentions decline in relation to words associated with humanism and liberalism? The inclusion of the later DD provides yet more data to measure these conclusions against.

Stewart (2017: 214-215) also suggests that, beginning in 1865, Douglass’s political philosophy moved away from the need for federal action to advocating more of a laissez-faire policy toward the African American community. Are there more occurences of words connoting interventionist policy in NLFD/MBMF opposed to LTFD/DD?

```{r}

# TBC 

# split autobiographical works into chapter positions #

NLFD.v <- file.names.v[[1]]
start.v <- which(NLFD.v == "CHAPTER 1")
end.v <- which(NLF.v == "I subscribe myself")
novel.lines.v <- NLFD.v[start.v: end.v]
novel.lines.v <- unlist(novel.lines.v)
chap.positions.v <- grep("^CHAPTER \\d", novel.lines.v)
last.position.v <- length(novel.lines.v)
chap.positions.v <- c(chap.positions.v, last.position.v)
# convert to table of character vectors per chapter
NLFD.raws.l <- list()
for(i in 1: length(chap.positions.v)) {
  if (i!=length(chap.positions.v)) {
    chapter.title <- novel.lines.v[chap.positions.v[i]]
    start <- chap.positions.v [i] + 1
    end <- chap.positions.v [i + 1] - 1
    chapter.lines.v <- novel.lines.v[start:end]
    chapter.words.v <- tolower(paste(chapter.lines.v, 
                                     collapse = ""))
    chapter.words.l <- strsplit(chapter.words.v, "\\w")
    chapter.words.v <- unlist(chapter.words.l)
    chapter.words.v <- chapter.words.v[which
                                       (chapter.words.v!= "")]
    chapter.freqs.t <- table(chapter.words.v)
    NLFD.raws.l[[chapter.title]] <- chapter.freqs.t
  }
}

# first measure the occurences of religious words per autobiography #

religion.v <- length(NLFD.v[NLFD.v == "God", "prayer", "religion", "church"])
total.words.v <- length(religion.v)
religion.v / total.words.v

NLFD.chapter.rel.freqs.t <- 100*(NLFD.chapter.freqs.t/sum(NLFD.chapter.freqs.t))
NLFD.chapter.freqs.l[[chapter.title]] <- NLFD.chapter.rel.freqs.
# how often is God mentioned per 100 words
sorted.NLFD.rel.freqs.t <- 100*(sorted.NLFD.freqs.t/sum(sorted.DD.freqs.t))
sorted.NLFD.rel.freqs.t["god"]

# repeat for each autobiography

faith.l <- lapply(c(NLFD.chapter.freqs.l, MBMF.chapter.freqs.l, LTFD.chapter.freqs.l, DD.freqs.l, '[', 'God')
faith.m <- do.call(rbind, faith.l)
faith.v <- faith.m[, 1]
plot_data <- data.frame(chapter = names(faith.v), frequency = faith.v)
ggplot(plot_data, aes(x = chapter, y = frequency, fill = chapter)) +
  geom_bar(stat = "identity") +
  labs(title = "Frequency of 'God' in Douglass Autobiography") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  facet_wrap(~chapter, scales = "free")

# create humanism.v vector

humanism.v <- which(NLFD.v == "science", "human", "abolition")
humanism.count.v <- rep(NA, length(n.time.v))
humanism.count.v[humanism.v] <- 1
humanism.v <- lapply(NLFD.freqs.l, '[', 'humanism')
humanism.m <- do.call(rbind, humanism.l)
humanism.v <- humanism.m, [, 1]

# map 'god' versus 'human' across Douglass autobiography using dispersion plot

n.time.v <- seq(1:length(autobiography.v))
god.v <- which(autobiography.v == "god")
g.count.v <- rep(NA,length(n.time.v))
g.count.v[god.v] <- 1
plot(w.count.v, main="Dispersion Plot of 'god' in Douglass Autobiography",
     xlab="Novel Time (words)", ylab="god mentions", type="h", ylim=c(0,1), yaxt='n')

man.v <- which(autobiography.v == "man")
m.count.v <- rep(NA,length(n.time.v))
m.count.v[man.v] <- 1
plot(a.count.v, main="Dispersion Plot of 'man' in Douglass Autobiography",
     xlab="Novel Time (words)", ylab="human mentions", type="h", ylim=c(0,1), yaxt='n')

god.human.m <- cbind(god.v, man.v)
dim(god.man.m)
colnames(god.man.m) <- c("god", "man")
barplot(god.man.m, beside=T, col="grey")

# correlate religious to humanism words using a randomised sample from df "faith" column against unrandomised "humanism" column, loop to iterate 10000 x and place into empty variable

belief.m <- cbind (humanism.v, faith.v)
dim(belief.m)
colnames(belief.m) <- c("god","humanism")
belief.m [which(is.na(belief.m))]
cor(belief.m)
cor.data.df <- as.data.frame(belief.m)
mycors.v <- NULLfor(i in 1:1000) {
  mycors.v <- c(mycors.v, cor(
    sample(cor.data.df$faith), 
    cor.data.df$science))
}
mean(mycors.v)

# visualise #

h <- hist(mycors.v, breaks=100, col="grey", 
          xlab="Correlation Between Faith and Humanism",
          main="Randomised Correlation Coefficients",
          plot=T) 
xfit <- seq(min(mycors.v),max(mycors.v),length=1000)
yfit <- dnorm(xfit,mean=mean(mycors.v),sd=sd(mycors.v))
yfit <- yfit*diff(h$mids[1:2])*length(mycors.v)
lines(xfit, yfit, col="black", lwd=2)
```

## Sentiment Analysis

Measure of Douglass's general impression in visiting the countries mentioned in DD, refer against a close reading of his intellectual biography.

```{r}
# packages # 

library(SentimentAnalysis)
quanteda.bundle <- c( "quanteda", "quanteda.textmodels",
                      "quanteda.textstats", "quanteda.textplots" )
install.packages(quanteda.bundle) # to break down size of quanteda package
library(tibble)
library(qdapDictionaries)
library(dplyr)
library(tidyr)
library(ggplot2)

# assigns GI_Dict (compatible for Quanteda) to text corpus #

text <- DD.v
corp <- corpus(text, text_field = "text")
dtm <- corp %>%
  dfm()
result <- dfm_lookup(dtm, dictionary = dictionary(DictionaryGI)) %>% 
  GI_dict = DictionaryGI %>%
  convert(to = "data.frame") %>%
  as_tibble()
result

result = result %>% mutate(length=ntoken(dtm))
result = result %>% mutate(sentiment1=(positive - negative) / (positive + negative))
result = result %>% mutate(sentiment2=(positive - negative) / length)
result = result %>% mutate(subjectivity=(positive + negative) / length)
result

result <- result %>% 
  mutate(length = ntoken(DD.dtm)) %>%
  mutate(sentiment1 = (positive - negative) / (positive + negative)) %>%
  mutate(sentiment2 = (positive - negative) / length) %>%
  mutate(subjectivity = (positive + negative) / length)
```

sentiment1 = positive words minus negative, divided by total sentiment words, -1 (only negative) and 1 (only positive)

sentiment2 = positive minus negative, divided by total number of document terms, accounting for document length

subjectivity = total sentiment over document

doc_id          negative positive length sentiment1 sentiment2 subjectivity

\<chr\>              \<dbl\>    \<dbl\>  \<int\>      \<dbl\>      \<dbl\>        \<dbl\>

1 Egypt.txt              93      121   3192      0.131    0.00877      0.0670

2 England.txt          15       39      898      0.444    0.0267        0.0601

3 France.txt            21       41    1261      0.323    0.0159        0.0492

4 Greece.txt             5       18      406      0.565    0.0320        0.0567

5 Ireland.txt              2         4      152      0.333    0.0132      0.0395

6 Italy.txt               132     259    5792      0.325    0.0219        0.0675

7 Switzerland.txt       2         6      110      0.5        0.0364        0.0727

8 Voyage.txt            28       76   1357      0.462    0.0354        0.0766

```{r}

# validation, finds terms of 'neutral' use and removes from dictionary, in the case 'much' ##

# error - current issue on textstat function #

HL_dict <- dictionary(list(positive=positive.words, negative=negation.words))
freqs = textstat_frequency(dtm)
freqs %>% as_tibble() %>% filter(feature %in% GI-dict$positive) # measures what words are influencing sentiment
positive.words = head(kwic(corp,'much', window = 4))
positive.cleaned = setdiff(positive.words, c("much")) # replace with examples
HL_dict2 = dictionary(list(positive=positive.cleaned, negative=negation.words))
freqs %>% as_tibble() %>% filter(feature %in% HL_dict$positive)
  
# creates a browser of coded red and green sentiment words for DD #
# error - issue with forming tcorpus #

library(corpustools)
t <- create_tcorpus(corp)
t$code_dictionary(GI_dict, column = 'lsd15'))
t$set('sentiment', 1, subset = lsd15 %in% c('positive', 'neg_negative'))
t$set('sentiment', -1, subset = lsd15 %in% c('negative', 'neg_positive'))
browse_texts(t, scale = 'sentiment')

# visualise in tidyverse # 

# error - issue with inner-join #

tidy_DD <- tidy(DD.dtm) %>%
  inner_join(get_sentiments("bing")),  %>%
  count(country, index = linenumber %/% 21, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative)
  
ggplot(tidy_DD, aes(index, sentiment, fill = country)) +
  geom_col(show.legend = FALSE)
  facet_wrap(~country, ncol = 2, scales = "free_x")

# emotional valence, Jockers #

install.packages("syuzhet")
library(syuzhet)
poa_word_v <- get_tokens(DD.v[[8]], pattern = "\\W")
syuzhet_vector <- get_sentiment(poa_word_v, method = "syuzhet")
mean(syuzhet_vector)
summary(syuzhet_vector)
plot(syuzhet_vector, 
     type = "h", 
     main = "Douglass Diary 1886-1887 - Voyage", 
     xlab = "Narrative Time", 
     ylab = "Emotional Valence"
) 
```

![Figure Three, Emotional valence of Douglass's 'City of Rome' Voyage in Travel Diary (1886-1887)](figures/Emotional Valence/Voyage - Emotional Valence.png)

\
\
\
