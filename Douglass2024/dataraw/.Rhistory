#ggplot(norm_frequency, aes(x = word)) +
#    geom_point(aes(y=`My Bondage (1855)`))#, colour = "coral")) +
#ggplot(norm_frequency, aes(x = word)) +
#    geom_point(aes(y=`Life and Times (1881)`))#, colour = "teal")) +
#    scale_color_gradient(low = "darkslategray4", high = "coral")
# visualization
library(reshape2)
# creating a subset excluding words that have a word frequency less than the cutoff:
cutoff <- 15
norm_freq_long <- norm_frequency %>% pivot_longer(cols = -c(word,
sum_word_counts,
"Travel Diary"),
names_to = "works",
values_to = "distance")
norm_freq_subset <- norm_freq_long[norm_freq_long$sum_word_counts > cutoff,]
# visualizing the data
ggplot(norm_freq_subset, aes(x = word, y=distance)) +
geom_point(data = transform(norm_freq_subset, "Travel Diary" = NULL),
color="purple") +
geom_point(aes(color=works, group =works, alpha = .0005)) +
facet_wrap(vars(works)) +
theme(axis.text.x = element_blank(),
axis.ticks.x = element_blank())
#ggplot(norm_frequency, aes(x = word)) +
#    geom_point(aes(y=`Narrative Life (1845)`))#, colour = "yellow")) +
#ggplot(norm_frequency, aes(x = word)) +
#    geom_point(aes(y=`My Bondage (1855)`))#, colour = "coral")) +
#ggplot(norm_frequency, aes(x = word)) +
#    geom_point(aes(y=`Life and Times (1881)`))#, colour = "teal")) +
#    scale_color_gradient(low = "darkslategray4", high = "coral")
# visualization
library(reshape2)
# creating a subset excluding words that have a word frequency less than the cutoff:
cutoff <- 15
norm_freq_long <- norm_frequency %>% pivot_longer(cols = -c(word,
sum_word_counts,
"Travel Diary"),
names_to = "works",
values_to = "distance")
norm_freq_subset <- norm_freq_long[norm_freq_long$sum_word_counts > cutoff,]
# visualizing the data
ggplot(norm_freq_subset, aes(x = word, y=distance)) +
geom_point(data = transform(norm_freq_subset, "Travel Diary"),
color="purple") +
geom_point(aes(color=works, group =works, alpha = .0005)) +
facet_wrap(vars(works)) +
theme(axis.text.x = element_blank(),
axis.ticks.x = element_blank())
#ggplot(norm_frequency, aes(x = word)) +
#    geom_point(aes(y=`Narrative Life (1845)`))#, colour = "yellow")) +
#ggplot(norm_frequency, aes(x = word)) +
#    geom_point(aes(y=`My Bondage (1855)`))#, colour = "coral")) +
#ggplot(norm_frequency, aes(x = word)) +
#    geom_point(aes(y=`Life and Times (1881)`))#, colour = "teal")) +
#    scale_color_gradient(low = "darkslategray4", high = "coral")
# visualization
library(reshape2)
# creating a subset excluding words that have a word frequency less than the cutoff:
cutoff <- 15
norm_freq_long <- norm_frequency %>% pivot_longer(cols = -c(word,
sum_word_counts,
"Travel Diary"),
names_to = "works",
values_to = "distance")
norm_freq_subset <- norm_freq_long[norm_freq_long$sum_word_counts > cutoff,]
# visualizing the data
ggplot(norm_freq_subset, aes(x = word, y=distance)) +
#geom_point(data = transform(norm_freq_subset, "Travel Diary"),
#           color="purple") +
geom_point(aes(color=works, group =works, alpha = .0005)) +
facet_wrap(vars(works)) +
theme(axis.text.x = element_blank(),
axis.ticks.x = element_blank())
#ggplot(norm_frequency, aes(x = word)) +
#    geom_point(aes(y=`Narrative Life (1845)`))#, colour = "yellow")) +
#ggplot(norm_frequency, aes(x = word)) +
#    geom_point(aes(y=`My Bondage (1855)`))#, colour = "coral")) +
#ggplot(norm_frequency, aes(x = word)) +
#    geom_point(aes(y=`Life and Times (1881)`))#, colour = "teal")) +
#    scale_color_gradient(low = "darkslategray4", high = "coral")
# visualization
library(reshape2)
# creating a subset excluding words that have a word frequency less than the cutoff:
cutoff <- 15
norm_freq_long <- norm_frequency %>% pivot_longer(cols = -c(word,
sum_word_counts,
"Travel Diary"),
names_to = "works",
values_to = "distance")
norm_freq_subset <- norm_freq_long[norm_freq_long$sum_word_counts > cutoff,]
# visualizing the data
ggplot(norm_freq_subset, aes(x = word)) +
#geom_point(data = transform(norm_freq_subset, "Travel Diary"),
#           color="Travel Diary") +
geom_point(aes(y= distance, color= works, group= works, alpha= .0005)) +
geom_point(aes(y="Travel Diary", color= "Travel Diary")) +
facet_wrap(vars(works)) +
theme(axis.text.x = element_blank(),
axis.ticks.x = element_blank())
View(norm_freq_subset)
View(norm_freq_subset)
# visualization
library(reshape2)
# creating a subset excluding words that have a word frequency less than the cutoff:
cutoff <- 15
norm_freq_long <- norm_frequency %>% pivot_longer(cols = -c(word,
sum_word_counts,
"Travel Diary"),
names_to = "works",
values_to = "distance")
norm_freq_subset <- norm_freq_long[norm_freq_long$sum_word_counts > cutoff,]
# visualizing the data
ggplot(norm_freq_subset, aes(x = word)) +
geom_point(aes(y= distance, color= works, group= works, alpha= .0005)) +
geom_point(aes(y=norm_freq_subset$"Travel Diary", color= "Travel Diary")) +
facet_wrap(vars(works)) +
theme(axis.text.x = element_blank(),
axis.ticks.x = element_blank())
#ggplot(norm_frequency, aes(x = word)) +
#    geom_point(aes(y=`Narrative Life (1845)`))#, colour = "yellow")) +
#ggplot(norm_frequency, aes(x = word)) +
#    geom_point(aes(y=`My Bondage (1855)`))#, colour = "coral")) +
#ggplot(norm_frequency, aes(x = word)) +
#    geom_point(aes(y=`Life and Times (1881)`))#, colour = "teal")) +
#    scale_color_gradient(low = "darkslategray4", high = "coral")
# visualization
library(reshape2)
# creating a subset excluding words that have a word frequency less than the cutoff:
cutoff <- 15
norm_freq_long <- norm_frequency %>% pivot_longer(cols = -c(word,
sum_word_counts,
"Travel Diary"),
names_to = "works",
values_to = "distance")
norm_freq_subset <- norm_freq_long[norm_freq_long$sum_word_counts > cutoff,]
# visualizing the data
ggplot(norm_freq_subset, aes(x = word)) +
geom_point(aes(y= distance, color= works, group= works), alpha= .0005) +
geom_point(aes(y=norm_freq_subset$"Travel Diary", color= "Travel Diary")) +
facet_wrap(vars(works)) +
theme(axis.text.x = element_blank(),
axis.ticks.x = element_blank())
#ggplot(norm_frequency, aes(x = word)) +
#    geom_point(aes(y=`Narrative Life (1845)`))#, colour = "yellow")) +
#ggplot(norm_frequency, aes(x = word)) +
#    geom_point(aes(y=`My Bondage (1855)`))#, colour = "coral")) +
#ggplot(norm_frequency, aes(x = word)) +
#    geom_point(aes(y=`Life and Times (1881)`))#, colour = "teal")) +
#    scale_color_gradient(low = "darkslategray4", high = "coral")
# visualization
library(reshape2)
# creating a subset excluding words that have a word frequency less than the cutoff:
cutoff <- 15
norm_freq_long <- norm_frequency %>% pivot_longer(cols = -c(word,
sum_word_counts,
"Travel Diary"),
names_to = "works",
values_to = "distance")
norm_freq_subset <- norm_freq_long[norm_freq_long$sum_word_counts > cutoff,]
# visualizing the data
ggplot(norm_freq_subset, aes(x = word)) +
geom_point(aes(y= distance, color= works, group= works, alpha= .0005)) +
geom_point(aes(y=norm_freq_subset$"Travel Diary", color= "Travel Diary")) +
facet_wrap(vars(works)) +
theme(axis.text.x = element_blank(),
axis.ticks.x = element_blank())
#ggplot(norm_frequency, aes(x = word)) +
#    geom_point(aes(y=`Narrative Life (1845)`))#, colour = "yellow")) +
#ggplot(norm_frequency, aes(x = word)) +
#    geom_point(aes(y=`My Bondage (1855)`))#, colour = "coral")) +
#ggplot(norm_frequency, aes(x = word)) +
#    geom_point(aes(y=`Life and Times (1881)`))#, colour = "teal")) +
#    scale_color_gradient(low = "darkslategray4", high = "coral")
# visualization
library(reshape2)
# creating a subset excluding words that have a word frequency less than the cutoff:
cutoff <- 15
norm_freq_long <- norm_frequency %>% pivot_longer(cols = -c(word,
sum_word_counts,
"Travel Diary"),
names_to = "works",
values_to = "distance")
norm_freq_subset <- norm_freq_long[norm_freq_long$sum_word_counts > cutoff,]
# visualizing the data
ggplot(norm_freq_subset, aes(x = word)) +
geom_point(aes(y= distance, color= works, group= works), alpha= .0005) +
geom_point(aes(y=norm_freq_subset$"Travel Diary", color= "Travel Diary")) +
facet_wrap(vars(works)) +
theme(axis.text.x = element_blank(),
axis.ticks.x = element_blank())
#ggplot(norm_frequency, aes(x = word)) +
#    geom_point(aes(y=`Narrative Life (1845)`))#, colour = "yellow")) +
#ggplot(norm_frequency, aes(x = word)) +
#    geom_point(aes(y=`My Bondage (1855)`))#, colour = "coral")) +
#ggplot(norm_frequency, aes(x = word)) +
#    geom_point(aes(y=`Life and Times (1881)`))#, colour = "teal")) +
#    scale_color_gradient(low = "darkslategray4", high = "coral")
# visualization
library(reshape2)
# creating a subset excluding words that have a word frequency less than the cutoff:
cutoff <- 15
norm_freq_long <- norm_frequency %>% pivot_longer(cols = -c(word,
sum_word_counts,
"Travel Diary"),
names_to = "works",
values_to = "distance")
norm_freq_subset <- norm_freq_long[norm_freq_long$sum_word_counts > cutoff,]
# visualizing the data
ggplot(norm_freq_subset, aes(x = word)) +
geom_point(aes(y= distance, color= works, group= works, alpha= .0005)) +
geom_point(aes(y=norm_freq_subset$"Travel Diary", color= "Travel Diary")) +
facet_wrap(vars(works)) +
theme(axis.text.x = element_blank(),
axis.ticks.x = element_blank())
#ggplot(norm_frequency, aes(x = word)) +
#    geom_point(aes(y=`Narrative Life (1845)`))#, colour = "yellow")) +
#ggplot(norm_frequency, aes(x = word)) +
#    geom_point(aes(y=`My Bondage (1855)`))#, colour = "coral")) +
#ggplot(norm_frequency, aes(x = word)) +
#    geom_point(aes(y=`Life and Times (1881)`))#, colour = "teal")) +
#    scale_color_gradient(low = "darkslategray4", high = "coral")
# visualization
library(reshape2)
# creating a subset excluding words that have a word frequency less than the cutoff:
cutoff <- 15
norm_freq_long <- norm_frequency %>% pivot_longer(cols = -c(word,
sum_word_counts,
"Travel Diary"),
names_to = "works",
values_to = "distance")
norm_freq_subset <- norm_freq_long[norm_freq_long$sum_word_counts > cutoff,]
# visualizing the data
ggplot(norm_freq_subset, aes(x = word)) +
geom_point(aes(y= distance, color= works, group= works, alpha= .0005)) +
geom_point(aes(y=norm_freq_subset$"Travel Diary", color= "Travel Diary")) +
facet_wrap(vars(works)) +
guides(alpha = FALSE) +
theme(axis.text.x = element_blank(),
axis.ticks.x = element_blank())
#ggplot(norm_frequency, aes(x = word)) +
#    geom_point(aes(y=`Narrative Life (1845)`))#, colour = "yellow")) +
#ggplot(norm_frequency, aes(x = word)) +
#    geom_point(aes(y=`My Bondage (1855)`))#, colour = "coral")) +
#ggplot(norm_frequency, aes(x = word)) +
#    geom_point(aes(y=`Life and Times (1881)`))#, colour = "teal")) +
#    scale_color_gradient(low = "darkslategray4", high = "coral")
# visualization
library(reshape2)
# creating a subset excluding words that have a word frequency less than the cutoff:
cutoff <- 15
norm_freq_long <- norm_frequency %>% pivot_longer(cols = -c(word,
sum_word_counts,
"Travel Diary"),
names_to = "works",
values_to = "distance")
norm_freq_subset <- norm_freq_long[norm_freq_long$sum_word_counts > cutoff,]
# visualizing the data
ggplot(norm_freq_subset, aes(x = word)) +
geom_point(aes(y= distance, color= works, group= works, alpha= .0005)) +
geom_point(aes(y= norm_freq_subset$"Travel Diary", color= "Travel Diary")) +
facet_wrap(vars(works)) +
guides(alpha = FALSE) +
labs(x= "Words", y= "Similarity to Travel Diary")
theme(axis.text.x = element_blank(),
axis.ticks.x = element_blank())
#ggplot(norm_frequency, aes(x = word)) +
#    geom_point(aes(y=`Narrative Life (1845)`))#, colour = "yellow")) +
#ggplot(norm_frequency, aes(x = word)) +
#    geom_point(aes(y=`My Bondage (1855)`))#, colour = "coral")) +
#ggplot(norm_frequency, aes(x = word)) +
#    geom_point(aes(y=`Life and Times (1881)`))#, colour = "teal")) +
#    scale_color_gradient(low = "darkslategray4", high = "coral")
# visualization
library(reshape2)
# creating a subset excluding words that have a word frequency less than the cutoff:
cutoff <- 15
norm_freq_long <- norm_frequency %>% pivot_longer(cols = -c(word,
sum_word_counts,
"Travel Diary"),
names_to = "works",
values_to = "distance")
norm_freq_subset <- norm_freq_long[norm_freq_long$sum_word_counts > cutoff,]
# visualizing the data
ggplot(norm_freq_subset, aes(x = word)) +
geom_point(aes(y= distance, color= works, group= works, alpha= .0005)) +
geom_point(aes(y= norm_freq_subset$"Travel Diary", color= "Travel Diary")) +
facet_wrap(vars(works)) +
guides(alpha = FALSE) +
labs(x= "Words", y= "Similarity to Travel Diary") +
theme(axis.text.x = element_blank(),
axis.ticks.x = element_blank())
#ggplot(norm_frequency, aes(x = word)) +
#    geom_point(aes(y=`Narrative Life (1845)`))#, colour = "yellow")) +
#ggplot(norm_frequency, aes(x = word)) +
#    geom_point(aes(y=`My Bondage (1855)`))#, colour = "coral")) +
#ggplot(norm_frequency, aes(x = word)) +
#    geom_point(aes(y=`Life and Times (1881)`))#, colour = "teal")) +
#    scale_color_gradient(low = "darkslategray4", high = "coral")
source("~/.active-rstudio-document", echo=TRUE)
View(frequency2)
View(norm_freq_long)
View(norm_frequency)
View(norm_freq_subset)
# visualization
library(reshape2)
# creating a subset excluding words that have a word frequency less than the cutoff:
cutoff <- 15
norm_freq_long <- norm_frequency %>% pivot_longer(cols = -c(word,
sum_word_counts,
"Travel Diary"),
names_to = "works",
values_to = "distance")
norm_freq_subset <- norm_freq_long[norm_freq_long$sum_word_counts > cutoff,]
# visualizing the data
ggplot(norm_freq_subset, aes(x = word)) +
geom_point(aes(y= distance, color= works, group= works, alpha= .0005)) +
geom_point(aes(y= norm_freq_subset$"Travel Diary", color= "Travel Diary")) +
facet_wrap(vars(works)) +
guides(alpha = FALSE) +
labs(x= "Words", y= "Similarity to Travel Diary") +
theme(axis.text.x = element_blank(),
axis.ticks.x = element_blank())
#ggplot(norm_frequency, aes(x = word)) +
#    geom_point(aes(y=`Narrative Life (1845)`))#, colour = "yellow")) +
#ggplot(norm_frequency, aes(x = word)) +
#    geom_point(aes(y=`My Bondage (1855)`))#, colour = "coral")) +
#ggplot(norm_frequency, aes(x = word)) +
#    geom_point(aes(y=`Life and Times (1881)`))#, colour = "teal")) +
#    scale_color_gradient(low = "darkslategray4", high = "coral")
# visualization
library(reshape2)
# creating a subset excluding words that have a word frequency less than the cutoff:
cutoff <- 5
norm_freq_long <- norm_frequency %>% pivot_longer(cols = -c(word,
sum_word_counts,
"Travel Diary"),
names_to = "works",
values_to = "distance")
norm_freq_subset <- norm_freq_long[norm_freq_long$sum_word_counts > cutoff,]
# visualizing the data
ggplot(norm_freq_subset, aes(x = word)) +
geom_point(aes(y= distance, color= works, group= works, alpha= .0005)) +
geom_point(aes(y= norm_freq_subset$"Travel Diary", color= "Travel Diary")) +
facet_wrap(vars(works)) +
guides(alpha = FALSE) +
labs(x= "Words", y= "Similarity to Travel Diary") +
theme(axis.text.x = element_blank(),
axis.ticks.x = element_blank())
#ggplot(norm_frequency, aes(x = word)) +
#    geom_point(aes(y=`Narrative Life (1845)`))#, colour = "yellow")) +
#ggplot(norm_frequency, aes(x = word)) +
#    geom_point(aes(y=`My Bondage (1855)`))#, colour = "coral")) +
#ggplot(norm_frequency, aes(x = word)) +
#    geom_point(aes(y=`Life and Times (1881)`))#, colour = "teal")) +
#    scale_color_gradient(low = "darkslategray4", high = "coral")
# visualization
library(reshape2)
# creating a subset excluding words that have a word frequency less than the cutoff:
cutoff <- 5
norm_freq_long <- norm_frequency %>% pivot_longer(cols = -c(word,
sum_word_counts,
"Travel Diary"),
names_to = "Works",
values_to = "distance")
norm_freq_subset <- norm_freq_long[norm_freq_long$sum_word_counts > cutoff,]
# visualizing the data
ggplot(norm_freq_subset, aes(x = word)) +
geom_point(aes(y= distance, color= Works, group= Works, alpha= .0005)) +
geom_point(aes(y= norm_freq_subset$"Travel Diary", color= "Travel Diary")) +
facet_wrap(vars(Works)) +
guides(alpha = FALSE) +
labs(x= "Words", y= "Similarity to Travel Diary") +
theme(axis.text.x = element_blank(),
axis.ticks.x = element_blank())
#ggplot(norm_frequency, aes(x = word)) +
#    geom_point(aes(y=`Narrative Life (1845)`))#, colour = "yellow")) +
#ggplot(norm_frequency, aes(x = word)) +
#    geom_point(aes(y=`My Bondage (1855)`))#, colour = "coral")) +
#ggplot(norm_frequency, aes(x = word)) +
#    geom_point(aes(y=`Life and Times (1881)`))#, colour = "teal")) +
#    scale_color_gradient(low = "darkslategray4", high = "coral")
# visualization
library(reshape2)
# creating a subset excluding words that have a word frequency less than the cutoff:
cutoff <- 15
norm_freq_long <- norm_frequency %>% pivot_longer(cols = -c(word,
sum_word_counts,
"Travel Diary"),
names_to = "Works",
values_to = "distance")
norm_freq_subset <- norm_freq_long[norm_freq_long$sum_word_counts > cutoff,]
# visualizing the data
ggplot(norm_freq_subset, aes(x = word)) +
geom_point(aes(y= distance, color= Works, group= Works, alpha= .0005)) +
geom_point(aes(y= norm_freq_subset$"Travel Diary", color= "Travel Diary")) +
facet_wrap(vars(Works)) +
guides(alpha = FALSE) +
labs(x= "Words", y= "Similarity to Travel Diary") +
theme(axis.text.x = element_blank(),
axis.ticks.x = element_blank())
#ggplot(norm_frequency, aes(x = word)) +
#    geom_point(aes(y=`Narrative Life (1845)`))#, colour = "yellow")) +
#ggplot(norm_frequency, aes(x = word)) +
#    geom_point(aes(y=`My Bondage (1855)`))#, colour = "coral")) +
#ggplot(norm_frequency, aes(x = word)) +
#    geom_point(aes(y=`Life and Times (1881)`))#, colour = "teal")) +
#    scale_color_gradient(low = "darkslategray4", high = "coral")
knitr::opts_chunk$set(echo=TRUE)
getwd()
setwd("~/Documents/Douglass2024/dataraw")
############# Word Frequency Use Across Douglass Autobiography ##############
# uploading packages and set working directory #
library(readtext)
library(gutenbergr)
library(tidyverse)
library(tidytext)
library(scales)
library(forcats)
library(ggplot2)
library(tm)
# upload biographies and convert to tidytext format, count word instances and take mean usage #
NLFD.v <- gutenberg_download(23)
tidy_NLFD <- NLFD.v %>%
unnest_tokens(word, text) %>%
anti_join(stop_words) %>%
count(word, sort = TRUE) %>%
rename(word_count = n)
mean_wf <- mean(tidy_NLFD$word_count)
MBMF.v <- gutenberg_download(202)
tidy_MBMF <- MBMF.v %>%
unnest_tokens(word, text) %>%
anti_join(stop_words) %>%
count(word, sort = TRUE) %>%
rename(word_count = n)
mean_wf <- mean(tidy_MBMF$word_count)
LTFD.v <- readtext("~/Documents/Douglass2024/dataraw/LTFD.rtf")
View(norm_freq_long)
# visualization
library(reshape2)
# creating a subset excluding words that have a word frequency less than the cutoff:
cutoff <- 15
norm_freq_long <- norm_frequency %>% pivot_longer(cols = -c(word,
sum_word_counts,
"Travel Diary"),
names_to = "Works",
values_to = "distance")
norm_freq_subset <- norm_freq_long[norm_freq_long$sum_word_counts > cutoff,]
# visualizing the data
ggplot(norm_freq_subset, aes(x = word)) +
geom_point(aes(y= distance, color= Works, group= Works, alpha= .0005)) +
geom_point(aes(y= norm_freq_subset$"Travel Diary", color= "Travel Diary")) +
facet_wrap(vars(Works)) +
guides(alpha = FALSE) +
labs(x= "Words", y= "Similarity to Travel Diary") +
theme(axis.text.x = element_blank(),
axis.ticks.x = element_blank())
## Additional Word Frequency Info
# calculating for total sum of words and accounting for total word size (including cutoff).
frequency_subset <- frequency2[frequency2$sum_word_counts > cutoff,]
View(frequency_subset)
# visualization
library(reshape2)
# creating a subset excluding words that have a word frequency less than the cutoff:
cutoff <- 15
norm_freq_long <- norm_frequency %>% pivot_longer(cols = -c(word,
sum_word_counts,
"Travel Diary"),
names_to = "Works",
values_to = "distance")
norm_freq_subset <- norm_freq_long[norm_freq_long$sum_word_counts > cutoff,]
# visualizing the data
ggplot(norm_freq_subset, aes(x = word)) +
geom_point(aes(y= distance, color= Works, group= Works, alpha= .0005)) +
geom_point(aes(y= norm_freq_subset$"Travel Diary", color= "Travel Diary")) +
facet_wrap(vars(Works)) +
guides(alpha = FALSE) +
labs(x= "Words", y= "Similarity to Travel Diary") +
theme(axis.text.x = element_blank(),
axis.ticks.x = element_blank())
## Additional Word Frequency Info
# calculating for total sum of words and accounting for total word size (including cutoff).
frequency_subset <- frequency2[frequency2$sum_word_counts > cutoff,]
frequencySum <- colSums(frequency_subset)
## Additional Word Frequency Info
# calculating for total sum of words and accounting for total word size (including cutoff).
frequency_subset <- frequency2[frequency2$sum_word_counts > cutoff,]
frequencySum <- colSums(frequency_subset)
View(frequency_subset)
## Additional Word Frequency Info
# calculating for total sum of words and accounting for total word size (including cutoff).
frequency_subset <- frequency2[frequency2$sum_word_counts > cutoff,]
frequencySum <- frequency_subset%>% mutate(sum = colSums(frequency_subset))
## Additional Word Frequency Info
# calculating for total sum of words and accounting for total word size (including cutoff).
frequency_subset <- frequency2[frequency2$sum_word_counts > cutoff,]
frequencySum <- colSums(frequency_subset)
## Additional Word Frequency Info
# calculating for total sum of words and accounting for total word size (including cutoff).
frequency_subset <- frequency2[frequency2$sum_word_counts > cutoff,]
frequencySum <- sum(frequency_subset)
## Additional Word Frequency Info
# calculating for total sum of words and accounting for total word size (including cutoff).
frequency_subset <- frequency2[frequency2$sum_word_counts > cutoff,] %>%
mutate(word = NULL)
frequencySum <- colSums(frequency_subset)
View(frequency_subset)
## Additional Word Frequency Info
# calculating for total sum of words and accounting for total word size (including cutoff).
frequency_subset <- frequency2[frequency2$sum_word_counts > cutoff,]
frequencySum <- colSums(frequency_subset%>%
mutate(word = NULL))
View(frequency_subset)
